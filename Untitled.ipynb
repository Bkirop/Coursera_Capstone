{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report | Capstone Project – Predicting Car Accident Severity in Seattle Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction: Business Problem](#introduction)\n",
    "* [Data](#data)\n",
    "* [Methodology](#methodology)\n",
    "* [Analysis](#analysis)\n",
    "* [Results and Discussion](#results)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction:\n",
    "\n",
    "The purpose of this Project is to create a model for predicting car  accident severity by applying machine learning techniques.  It will help people and organizations to understand the impact of exogenous variables such as environmental ones or road conditions and more or less the endogenous ones such as the speeding or under influence factor. A better understanding of the impact of available variables might provide some guidance on efficient resource allocation or policy development.In addition, describing the importance and the impact of the variables at hand on accident occurrence might help insurance companies to review their cost and premium allocations.\n",
    "\n",
    "The target audiences of this study are those people who really care about the traffic records, especially in the transportation department. Also, we want to figure out the reason for collisions and help to reduce accidents in the future.\n",
    "\n",
    "The whole analysis of the data set is done using Python language and its libraries. The report, notebooks, code, and data are available on my GitHub profile. The goal of the project is to predict the severity of the crash and which variables influence the accident occurrence.  \n",
    "\n",
    "\n",
    "## 2. Data Section\n",
    "\n",
    "Data Link: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M \n",
    "\n",
    "I am using the provided Data-Collisions.csv dataset.The data was collected by Seattle SPOT Traffic Management.This dataset is updated weekly and is from 2004 to present.The dataset has an initial total of 194,673 observations characterized by 38 different features. The data set contains data that might contribute to determining the severity of an accident which include: the number of vehicles involved, location where the accident occurred, the weather condition, light condition, road condition, junction, number of people etc. \n",
    "\n",
    "Other features are both numerical and categorical. We have the environment, accident, location, type of location and accident, people and cars involved, and other accident describing features. The GitHub repository includes the data set in the csv format and a pdf file with a detailed description of the features and values included in the dataset. Therefore, please check the pdf file whenever is necessary to clarify the nature of the features or values.\n",
    "\n",
    "The dataset contains many categorical features. Some of them take nominal values, thus no natural order to their values is present, instead are used for encoding purposes only, however other features describe the encodings. “SDOT_COLDESC” and “SDOT_COLCODE” are an example of such features. Either feature will have to be hot encoded eventually, thus as of now the preferred feature to keep will be the one that comes as a description, while another one will be dropped.\n",
    "\n",
    "There are features that can be derived from one or more categorical features or values overlaps. Comparing “WEATHER” and “ROADCONDITION”, the “Rain” value relates to “Wet” condition. Thus, there is a strong correlation between some features, however, some of them will be kept and used to extract the most intelligence during the data exploration.  \n",
    "Eventually, those features that present excessive correlation will be removed as they are redundant and are harmful for the model.\n",
    "The numerical features presented in the dataset are counters that indicate the number of pedestrians, cyclists, or vehicles involved in an accident.\n",
    "\n",
    "\n",
    "## 3. Methodology Section\n",
    "\n",
    "The goal of the project is to predict the severity of the crash and which variables influence the accident occurrence. In the data set, the target variable is called SEVERITYDESC and takes two values: “Property Damage Only Collision” and “Injury Collision”.\n",
    " \n",
    "To achieve this objective, the following steps will be taken:\n",
    "-\tFeature Exploration (with data cleaning)\n",
    "-\tDimensionality Reduction\n",
    "-\tModel Building\n",
    "-\tOptimization and final model selection. \n",
    "\n",
    "#### Feature Exploration:\n",
    "To compare the similarities of two cities, we decided to explore neighborhoods, segment them, and group them into clusters to find similar neighborhoods in a big city like New York and Toronto. To be able to do that, we need to cluster data which is a form of unsupervised machine learning: k-means clustering algorithm.\n",
    "\n",
    "\n",
    "#### Dimensionality Reduction:\n",
    "Using credentials of Foursquare API features of near-by places of the neighborhoods would be mined. Due to http request limitations the number of places per neighborhood parameter would reasonably be set to 100 and the radius parameter would be set to 500.\n",
    "\n",
    "Our goal is to predict the severity of an accident , in the dataset the target variable is called “SEVERITYDESC“ And It takes two levels i.e. injury collisions and property damage only collision represented by codes 1& 2 respectively. To achieve our goal, we will go through the following steps;\n",
    "•\tFeature exploration( with data cleaning)\n",
    "•\tDimensionality  reduction\n",
    "#### Model building\n",
    "#### Optimization and final model selection\n",
    "## 4. Results Section\n",
    "\n",
    "\n",
    "\n",
    "#### The Location:\n",
    "Scarborough is a popular destination for new immigrants in Canada to reside. As a result, it is one of the most diverse and multicultural areas in the Greater Toronto Area, being home to various religious groups and places of worship. Although immigration has become a hot topic over the past few years with more governments seeking more restrictions on immigrants and refugees, the general trend of immigration into Canada has been one of on the rise.\n",
    "\n",
    "#### Foursquare API:\n",
    "This project have used Four-square API as its prime data gathering source as it has a database of millions of places, especially their places API which provides the ability to perform location search, location sharing and details about a business.\n",
    "\n",
    "\n",
    "\n",
    "## 5. Discussion Section\n",
    "\n",
    "#### Problem Which Tried to Solve:\n",
    "The major purpose of this project, is to suggest a better neighborhood in a new city for the person who are shiffting there. Social presence in society in terms of like minded people. Connectivity to the airport, bus stand, city center, markets and other daily needs things nearby.\n",
    "\n",
    "1. Sorted list of house in terms of housing prices in a ascending or descending order\n",
    "2. Sorted list of schools in terms of location, fees, rating and reviews\n",
    "\n",
    "\n",
    "\n",
    "## 6. Conclusion Section\n",
    "\n",
    "In this project, using k-means cluster algorithm I separated the neighborhood into 10(Ten) different clusters and for 103 different lattitude and logitude from dataset, which have very-similar neighborhoods around them. Using the charts above results presented to a particular neighborhood based on average house prices and school rating have been made.\n",
    "\n",
    "I feel rewarded with the efforts and believe this course with all the topics covered is well worthy of appreciation.\n",
    "This project has shown me a practical application to resolve a real situation that has impacting personal and financial impact using Data Science tools.\n",
    "The mapping with Folium is a very powerful technique to consolidate information and make the analysis and decision better with confidence.\n",
    "\n",
    "\n",
    "#### Future Works:\n",
    "This project can be continued for making it more precise in terms to find best house in Scarborough. Best means on the basis of all required things(daily needs or things we need to live a better life) around and also in terms of cost effective. \n",
    "\n",
    "\n",
    "#### Libraries Which are Used to Develope the Project:\n",
    "\n",
    "> Pandas: For creating and manipulating dataframes.\n",
    ">\n",
    "> Folium: Python visualization library would be used to visualize the neighborhoods cluster distribution of using interactive leaflet map.\n",
    "> \n",
    "> Scikit Learn: For importing k-means clustering.\n",
    ">\n",
    "> JSON: Library to handle JSON files.\n",
    ">\n",
    "> XML: To separate data from presentation and XML stores data in plain text format.\n",
    "> \n",
    "> Geocoder: To retrieve Location Data.\n",
    "> \n",
    "> Beautiful Soup and Requests: To scrap and library to handle http requests.\n",
    "> \n",
    "> Matplotlib: Python Plotting Module.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
